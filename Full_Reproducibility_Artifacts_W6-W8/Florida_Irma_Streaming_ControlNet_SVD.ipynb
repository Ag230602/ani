{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Florida Irma Streaming LoRA → ControlNet (Depth) → Stable Video Diffusion "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Runtime check (GPU strongly recommended)\n",
        "import torch, sys\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\" Switch to GPU: Runtime → Change runtime type → GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Mount Google Drive (outputs only)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Florida_Irma_Project\"\n",
        "OUT_DIR  = f\"{BASE_DIR}/out\"\n",
        "LORA_DIR = f\"{BASE_DIR}/lora_irma_fl\"\n",
        "SCR_DIR  = \"/dev/shm/irma_stream\"   # RAM disk (not persisted)\n",
        "DEPTH_DIR= f\"{BASE_DIR}/control_inputs/depth\"\n",
        "\n",
        "import os, json\n",
        "for p in [BASE_DIR, OUT_DIR, LORA_DIR, DEPTH_DIR]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "os.makedirs(SCR_DIR, exist_ok=True)\n",
        "\n",
        "print(json.dumps({\n",
        "    \"BASE_DIR\": BASE_DIR,\n",
        "    \"OUT_DIR\": OUT_DIR,\n",
        "    \"LORA_DIR\": LORA_DIR,\n",
        "    \"SCR_DIR (RAM)\": SCR_DIR,\n",
        "    \"DEPTH_DIR\": DEPTH_DIR\n",
        "}, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Install dependencies\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install \"diffusers>=0.31\" transformers accelerate safetensors xformers\n",
        "!pip -q install sentencepiece ftfy datasets tqdm einops peft\n",
        "!pip -q install opencv-python imageio imageio-ffmpeg numpy pillow requests beautifulsoup4 humanize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Hugging Face authentication\n",
        "Accept licenses for:\n",
        "- `runwayml/stable-diffusion-v1-5`\n",
        "- `stabilityai/stable-video-diffusion-img2vid-xt`\n",
        "- `lllyasviel/sd-controlnet-depth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Login to Hugging Face (paste your token)\n",
        "from huggingface_hub import login\n",
        "HF_TOKEN = \"\"  #@param {type:\"string\"}\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "    print(\" Logged in to Hugging Face\")\n",
        "else:\n",
        "    print(\" Paste your HF token in HF_TOKEN and re-run this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Stream/scrape Irma images (kept in RAM only)\n",
        "We fetch from news galleries (Guardian, Atlantic, Tampa Bay Times), dedupe by content-hash,\n",
        "resize to 512×512, and save to `/dev/shm/irma_stream` (RAM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Scrape → dedupe → preprocess (512×512) into RAM (/dev/shm)\n",
        "import os, hashlib, io, requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "\n",
        "SCR_DIR = \"/dev/shm/irma_stream\"\n",
        "os.makedirs(SCR_DIR, exist_ok=True)\n",
        "\n",
        "URLS = [\n",
        "  \"https://www.theguardian.com/world/gallery/2017/sep/12/in-pictures-the-aftermath-of-hurricane-irma-in-florida\",\n",
        "  \"https://www.theatlantic.com/photo/2017/09/photos-of-the-damage-left-by-hurricane-irma-in-florida/539421/\",\n",
        "  \"https://projects.tampabay.com/projects/2017/hurricane-irma/photo-story/irma-damage/\"\n",
        "]\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "seen_hashes = set()\n",
        "kept = 0\n",
        "max_keep = 160\n",
        "\n",
        "def normalize(u: str):\n",
        "    if u.startswith(\"//\"): return \"https:\" + u\n",
        "    return u\n",
        "\n",
        "def add_candidate(srcset_or_url, bag: set):\n",
        "    if not srcset_or_url: return\n",
        "    s = srcset_or_url.strip()\n",
        "    if \" \" in s and \"srcset\" in srcset_or_url:\n",
        "        s = s.split(\",\")[-1].strip().split(\" \")[0]\n",
        "    s = normalize(s)\n",
        "    if s.startswith(\"http\"):\n",
        "        bag.add(s)\n",
        "\n",
        "for page in URLS:\n",
        "    try:\n",
        "        html = requests.get(page, headers=headers, timeout=20).text\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        candidates = set()\n",
        "        for img in soup.find_all(\"img\"):\n",
        "            for k in [\"src\", \"data-src\", \"data-original\", \"data-srcset\", \"srcset\"]:\n",
        "                add_candidate(img.get(k), candidates)\n",
        "        for a in soup.find_all(\"a\", href=True):\n",
        "            h = normalize(a[\"href\"])\n",
        "            if any(h.lower().endswith(ext) for ext in [\".jpg\",\".jpeg\",\".png\",\".webp\"]):\n",
        "                candidates.add(h)\n",
        "        for url in list(candidates):\n",
        "            if kept >= max_keep: break\n",
        "            try:\n",
        "                r = requests.get(url, headers=headers, timeout=20)\n",
        "                if r.status_code != 200 or \"image\" not in r.headers.get(\"Content-Type\",\"\"):\n",
        "                    continue\n",
        "                b = r.content\n",
        "                h = hashlib.sha256(b).hexdigest()\n",
        "                if h in seen_hashes: \n",
        "                    continue\n",
        "                seen_hashes.add(h)\n",
        "                im = Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
        "                im = im.resize((512,512))\n",
        "                fname = os.path.join(SCR_DIR, f\"irma_{h[:16]}.jpg\")\n",
        "                im.save(fname, quality=92)\n",
        "                kept += 1\n",
        "            except Exception:\n",
        "                pass\n",
        "        if kept >= max_keep: break\n",
        "    except Exception as e:\n",
        "        print(\"Skip:\", page, \"→\", e)\n",
        "\n",
        "print(f\" Collected {kept} images into {SCR_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Auto-caption scraped images (short documentary prompts)\n",
        "import os, glob, random, codecs\n",
        "SCR_DIR = \"/dev/shm/irma_stream\"\n",
        "TEMPLATE = [\n",
        "  \"Florida after Hurricane Irma, heavy damage, flooded streets, documentary photo\",\n",
        "  \"Post-Irma destruction in the Florida Keys, debris and broken piers, overcast\",\n",
        "  \"Hurricane Irma aftermath in Miami, damaged buildings, downed trees, realistic\",\n",
        "  \"Naples coastline after Irma, storm surge residue, scattered wreckage, realism\"\n",
        "]\n",
        "wrote = 0\n",
        "for img in glob.glob(os.path.join(SCR_DIR, \"*.jpg\")):\n",
        "    base, _ = os.path.splitext(img)\n",
        "    cap = base + \".txt\"\n",
        "    if not os.path.exists(cap):\n",
        "        with codecs.open(cap, \"w\", \"utf-8\") as f:\n",
        "            f.write(random.choice(TEMPLATE))\n",
        "        wrote += 1\n",
        "print(f\"Caption stubs written: {wrote}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Fetch LoRA training script (Diffusers)\n",
        "import os, requests\n",
        "SCRIPTS = f\"{BASE_DIR}/scripts\"\n",
        "os.makedirs(SCRIPTS, exist_ok=True)\n",
        "url = \"https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora.py\"\n",
        "dst = f\"{SCRIPTS}/train_text_to_image_lora.py\"\n",
        "if not os.path.exists(dst):\n",
        "    open(dst,\"wb\").write(requests.get(url).content)\n",
        "print(\"Saved:\", dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Compact LoRA training (~800 steps)\n",
        "import subprocess\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "DATA_DIR   = \"/dev/shm/irma_stream\"\n",
        "OUTPUT_DIR = f\"{LORA_DIR}\"\n",
        "cmd = [\n",
        "    \"accelerate\",\"launch\",\"--mixed_precision=fp16\",\n",
        "    f\"{BASE_DIR}/scripts/train_text_to_image_lora.py\",\n",
        "    \"--pretrained_model_name_or_path\", MODEL_NAME,\n",
        "    \"--train_data_dir\", DATA_DIR,\n",
        "    \"--caption_column\",\"text\",\n",
        "    \"--validation_prompt\",\"A wide shot of post-hurricane Irma destruction in the Florida Keys, flooded streets, broken docks, scattered debris, cloudy sky, documentary realism\",\n",
        "    \"--validation_epochs\",\"1000\",\n",
        "    \"--checkpointing_steps\",\"400\",\n",
        "    \"--seed\",\"42\",\n",
        "    \"--resolution\",\"512\",\n",
        "    \"--train_batch_size\",\"2\",\n",
        "    \"--gradient_accumulation_steps\",\"4\",\n",
        "    \"--learning_rate\",\"1e-4\",\n",
        "    \"--lr_scheduler\",\"cosine\",\n",
        "    \"--lr_warmup_steps\",\"0\",\n",
        "    \"--max_train_steps\",\"800\",\n",
        "    \"--rank\",\"8\",\n",
        "    \"--mixed_precision\",\"fp16\",\n",
        "    \"--output_dir\",OUTPUT_DIR\n",
        "]\n",
        "print(\" \".join(cmd))\n",
        "subprocess.run(cmd, check=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Build depth map (Drive source if present, else first scraped image)\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "import numpy as np, torch\n",
        "from transformers import pipeline as hf_pipeline\n",
        "\n",
        "drive_source = f\"{DEPTH_DIR}/source.jpg\"\n",
        "if os.path.exists(drive_source):\n",
        "    src_path = drive_source\n",
        "else:\n",
        "    imgs = sorted(glob.glob(\"/dev/shm/irma_stream/*.jpg\"))\n",
        "    assert imgs, \"No scraped images; re-run scraping.\"\n",
        "    src_path = imgs[0]\n",
        "print(\"Depth source:\", src_path)\n",
        "\n",
        "depth_estimator = hf_pipeline(\"depth-estimation\", model=\"Intel/dpt-hybrid-midas\")\n",
        "image = Image.open(src_path).convert(\"RGB\").resize((1024, 576))\n",
        "with torch.no_grad():\n",
        "    depth = depth_estimator(image)[\"depth\"]\n",
        "d = depth.resize(image.size)\n",
        "import numpy as np\n",
        "d = np.array(d)\n",
        "d = (d - d.min()) / (d.max() - d.min() + 1e-8)\n",
        "d = (d * 255).astype(np.uint8)\n",
        "depth_img = Image.fromarray(d)\n",
        "depth_png = f\"{DEPTH_DIR}/depth.png\"\n",
        "os.makedirs(DEPTH_DIR, exist_ok=True)\n",
        "depth_img.save(depth_png)\n",
        "print(\"Saved depth map:\", depth_png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  SD1.5 + ControlNet (Depth) + LoRA → Keyframe\n",
        "import torch, os\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler\n",
        "from PIL import Image\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/sd-controlnet-depth\", torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None\n",
        ").to(\"cuda\")\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "try:\n",
        "    pipe.load_lora_weights(LORA_DIR)\n",
        "    pipe.fuse_lora()\n",
        "    print(\" LoRA fused.\")\n",
        "except Exception as e:\n",
        "    print(\" LoRA fuse failed:\", e)\n",
        "\n",
        "control_image = Image.open(f\"{DEPTH_DIR}/depth.png\").convert(\"L\").resize((1024, 576))\n",
        "\n",
        "prompt = (\n",
        "  \"Documentary photo of post-hurricane Irma destruction in the Florida Keys, \"\n",
        "  \"flooded streets, broken docks and boats pushed ashore, scattered debris, \"\n",
        "  \"overcast sky, muted colors, realistic, high detail\"\n",
        ")\n",
        "negative = \"people, faces, text, watermark, logo, gore, fire, fantasy, cartoon\"\n",
        "\n",
        "gen = torch.Generator(device=\"cuda\").manual_seed(1234)\n",
        "image = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative,\n",
        "    image=control_image,\n",
        "    num_inference_steps=32,\n",
        "    guidance_scale=7.0,\n",
        "    controlnet_conditioning_scale=1.0,\n",
        "    generator=gen,\n",
        "    height=576, width=1024\n",
        ").images[0]\n",
        "\n",
        "import os\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "keyframe_path = f\"{OUT_DIR}/irma_florida_keyframe_controlnet.png\"\n",
        "image.save(keyframe_path)\n",
        "print(\"Saved keyframe:\", keyframe_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Stable Video Diffusion (img2vid-xt) → Animate keyframe\n",
        "import os, torch, imageio, numpy as np\n",
        "from PIL import Image\n",
        "from diffusers import StableVideoDiffusionPipeline\n",
        "\n",
        "KEYFRAME = f\"{OUT_DIR}/irma_florida_keyframe_controlnet.png\"\n",
        "assert os.path.exists(KEYFRAME), \"Missing keyframe; run previous cell.\"\n",
        "\n",
        "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-video-diffusion-img2vid-xt\",\n",
        "    torch_dtype=torch.float16, variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "img = Image.open(KEYFRAME).convert(\"RGB\").resize((1024, 576))\n",
        "\n",
        "motion_bucket_id = 224\n",
        "noise_aug_strength = 0.02\n",
        "num_frames = 25\n",
        "decoder_chunk_size = None\n",
        "\n",
        "with torch.autocast(\"cuda\"):\n",
        "    result = pipe(\n",
        "        img,\n",
        "        decode_chunk_size=decoder_chunk_size,\n",
        "        motion_bucket_id=motion_bucket_id,\n",
        "        noise_aug_strength=noise_aug_strength,\n",
        "        num_frames=num_frames\n",
        "    )\n",
        "\n",
        "frames = result.frames[0]\n",
        "frames_uint8 = [(f * 255).astype(np.uint8) for f in frames]\n",
        "mp4_path = f\"{OUT_DIR}/irma_florida_svd.mp4\"\n",
        "imageio.mimwrite(mp4_path, frames_uint8, fps=12, quality=8)\n",
        "print(\"Wrote video:\", mp4_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  List outputs and (optional) clean RAM images\n",
        "import os, glob, humanize\n",
        "from pathlib import Path\n",
        "\n",
        "def list_tree(root):\n",
        "    for p in sorted(Path(root).rglob(\"*\")):\n",
        "        if p.is_file():\n",
        "            sz = humanize.naturalsize(p.stat().st_size, gnu=True)\n",
        "            print(sz, \" - \", p)\n",
        "\n",
        "print(\"\\n=== LORA OUT ===\")\n",
        "list_tree(LORA_DIR)\n",
        "print(\"\\n=== OUT ===\")\n",
        "list_tree(OUT_DIR)\n",
        "\n",
        "CLEAN_RAM = True  #@param {type:\"boolean\"}\n",
        "if CLEAN_RAM:\n",
        "    import shutil\n",
        "    shutil.rmtree(\"/dev/shm/irma_stream\", ignore_errors=True)\n",
        "    print(\"\\n RAM dataset cleared from /dev/shm/irma_stream\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Florida_Irma_Streaming_ControlNet_SVD.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
