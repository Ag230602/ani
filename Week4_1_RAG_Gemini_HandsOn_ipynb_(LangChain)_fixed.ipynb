{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "UxjIZzz2qEZL",
   "metadata": {
    "id": "UxjIZzz2qEZL"
   },
   "source": [
    "# Week 4 — RAG with LangChain + Chroma\n",
    "Colab implementing a complete Retrieval-Augmented Generation (RAG) workflow:\n",
    "\n",
    "1) Install & setup  \n",
    "2) Load your project documents (PDF/Text/Markdown)  \n",
    "3) Chunk the documents  \n",
    "4) Build embeddings & Chroma vector DB  \n",
    "5) Connect an LLM (Gemini or Hugging Face)  \n",
    "6) Build RetrievalQA and ask domain-specific questions  \n",
    "7) Mini-experiments (Embedding swap, Chunk sensitivity)   \n",
    "8) Reproducibility log\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MDpcLHn8qEZN",
   "metadata": {
    "id": "MDpcLHn8qEZN"
   },
   "source": [
    "## 1) Install & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "M-xbvGY6qEZN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-xbvGY6qEZN",
    "outputId": "676967cb-2cda-4f2a-c86f-b2a3ba51c891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing: ['langchain>=0.2.15', 'langchain-community>=0.2.11', 'langchain-text-splitters>=0.2.2', 'langchain-huggingface>=0.1.0', 'chromadb>=0.5.5', 'sentence-transformers>=3.0.1', 'transformers>=4.44.2', 'accelerate>=0.34.0']\n",
      "Installing: ['langchain-google-genai>=2.0.0', 'google-generativeai>=0.7.2']\n",
      "Installing: ['pysqlite3-binary']\n",
      "✅ Installation complete.\n"
     ]
    }
   ],
   "source": [
    "# If you're on Colab, these installs will run in the current runtime.\n",
    "# If you're on local Jupyter, you can run them once in your environment.\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    print(\"Installing:\", pkgs)\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs, check=True)\n",
    "\n",
    "# Core libs (LangChain 0.2+ split packages; pin to stable ranges)\n",
    "pip_install([\n",
    "    \"langchain>=0.2.15\",\n",
    "    \"langchain-community>=0.2.11\",\n",
    "    \"langchain-text-splitters>=0.2.2\",\n",
    "    \"langchain-huggingface>=0.1.0\",\n",
    "    \"chromadb>=0.5.5\",\n",
    "    \"sentence-transformers>=3.0.1\",\n",
    "    \"transformers>=4.44.2\",\n",
    "    \"accelerate>=0.34.0\",\n",
    "])\n",
    "\n",
    "# Optional: Gemini (if you want to use Google Generative AI)\n",
    "try:\n",
    "    pip_install([\"langchain-google-genai>=2.0.0\", \"google-generativeai>=0.7.2\"])\n",
    "except Exception as e:\n",
    "    print(\"Could not install Gemini packages (optional):\", e)\n",
    "\n",
    "# Some platforms need this to enable SQLite for Chroma persistence\n",
    "try:\n",
    "    pip_install([\"pysqlite3-binary\"])\n",
    "except Exception as e:\n",
    "    print(\"Skipping pysqlite3-binary:\", e)\n",
    "\n",
    "print(\"✅ Installation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aJdqlhqEZO",
   "metadata": {
    "id": "e3aJdqlhqEZO"
   },
   "source": [
    "### Log Python, Torch, Transformers, SentenceTransformers, and Chroma versions (saved to `env_rag.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "BrGA--YpqEZO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrGA--YpqEZO",
    "outputId": "a9d54e4d-9b47-42e9-f9a2-3f7fd2174b27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-870873915.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved env to env_rag.json:\n",
      "{\n",
      "  \"timestamp\": \"2025-09-18T17:21:57.917400Z\",\n",
      "  \"python\": \"3.12.11\",\n",
      "  \"platform\": \"Linux-6.1.123+-x86_64-with-glibc2.35\",\n",
      "  \"torch\": \"2.8.0+cu126\",\n",
      "  \"cuda_available\": false,\n",
      "  \"cuda_device\": null,\n",
      "  \"transformers\": \"4.56.1\",\n",
      "  \"sentence_transformers\": \"5.1.0\",\n",
      "  \"chromadb\": \"1.1.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json, platform, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "env = {\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"python\": platform.python_version(),\n",
    "    \"platform\": platform.platform(),\n",
    "}\n",
    "\n",
    "# Optional libs\n",
    "try:\n",
    "    import torch\n",
    "    env[\"torch\"] = torch.__version__\n",
    "    env[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
    "    env[\"cuda_device\"] = torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "except Exception as e:\n",
    "    env[\"torch\"] = f\"unavailable ({e})\"\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    env[\"transformers\"] = transformers.__version__\n",
    "except Exception as e:\n",
    "    env[\"transformers\"] = f\"unavailable ({e})\"\n",
    "\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    env[\"sentence_transformers\"] = sentence_transformers.__version__\n",
    "except Exception as e:\n",
    "    env[\"sentence_transformers\"] = f\"unavailable ({e})\"\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    env[\"chromadb\"] = chromadb.__version__\n",
    "except Exception as e:\n",
    "    env[\"chromadb\"] = f\"unavailable ({e})\"\n",
    "\n",
    "# Save\n",
    "Path(\"runs\").mkdir(exist_ok=True)\n",
    "with open(\"env_rag.json\", \"w\") as f:\n",
    "    json.dump(env, f, indent=2)\n",
    "\n",
    "print(\"Saved env to env_rag.json:\")\n",
    "print(json.dumps(env, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnapZgr-qEZO",
   "metadata": {
    "id": "mnapZgr-qEZO"
   },
   "source": [
    "## 2) Load  Project Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aLurbLAqEZO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "4aLurbLAqEZO",
    "outputId": "938c048e-096a-4171-8964-0e2da57a2ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Please select your PDFs/TXT/MD files to upload...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c865cfba-4492-4fb3-ad12-954ef3cc2d5d\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c865cfba-4492-4fb3-ad12-954ef3cc2d5d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving mat-report_hurricane-irma_florida.pdf to mat-report_hurricane-irma_florida.pdf\n",
      "Saving NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf to NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf\n",
      "Saving annotated-Project Title (1).pdf to annotated-Project Title (1).pdf\n",
      "✅ Uploaded and saved: data/uploads/mat-report_hurricane-irma_florida.pdf\n",
      "✅ Uploaded and saved: data/uploads/NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf\n",
      "✅ Uploaded and saved: data/uploads/annotated-Project Title (1).pdf\n",
      "All files saved in: /content/data/uploads\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data/uploads\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"📂 Please select your PDFs/TXT/MD files to upload...\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for name, data in uploaded.items():\n",
    "    p = DATA_DIR / name\n",
    "    with open(p, \"wb\") as f:\n",
    "        f.write(data)\n",
    "    print(f\"✅ Uploaded and saved: {p}\")\n",
    "\n",
    "print(\"All files saved in:\", str(DATA_DIR.resolve()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lokqz0F5WMg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lokqz0F5WMg3",
    "outputId": "efadc310-6c0b-459c-fdb5-0ac5080049c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/310.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "P2bNL-u7qEZP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2bNL-u7qEZP",
    "outputId": "54cb27c5-984e-4293-a2bf-e921879a46f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 198 document chunks (pre-chunking).\n"
     ]
    }
   ],
   "source": [
    "# Load with LangChain loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs = []\n",
    "\n",
    "for path in sorted(DATA_DIR.glob(\"*\")):\n",
    "    p = str(path)\n",
    "    if path.suffix.lower() == \".pdf\":\n",
    "        try:\n",
    "            loader = PyPDFLoader(p)\n",
    "            docs.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"PDF load error for {p}:\", e)\n",
    "    elif path.suffix.lower() in [\".txt\", \".md\", \".markdown\"]:\n",
    "        try:\n",
    "            loader = TextLoader(p, encoding=\"utf-8\")\n",
    "            docs.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"Text load error for {p}:\", e)\n",
    "    else:\n",
    "        print(\"Skipping unsupported file type:\", p)\n",
    "\n",
    "print(f\"Loaded {len(docs)} document chunks (pre-chunking).\")\n",
    "if len(docs) == 0:\n",
    "    print(\"⚠️ No documents found. Please add at least three PDFs/TXT/MD files to data/uploads and re-run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eROXqpOnqEZP",
   "metadata": {
    "id": "eROXqpOnqEZP"
   },
   "source": [
    "## 3) Chunk the Documents (start with `chunk_size=500`, `chunk_overlap=100`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5OQ2aC7wqEZP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OQ2aC7wqEZP",
    "outputId": "d29236bd-aef2-41d1-85b2-d73d3b1632e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1071\n",
      "\n",
      "First chunk preview:\n",
      " Video Diffusion Models\n",
      "Jonathan Ho∗\n",
      "jonathanho@google.com\n",
      "Tim Salimans∗\n",
      "salimans@google.com\n",
      "Alexey Gritsenko\n",
      "agritsenko@google.com\n",
      "William Chan\n",
      "williamchan@google.com\n",
      "Mohammad Norouzi\n",
      "mnorouzi@google.com\n",
      "David J. Fleet\n",
      "davidfleet@google.com\n",
      "Abstract\n",
      "Generating temporally coherent high ﬁdelity video is an important milestone in\n",
      "generative modeling research. We make progress towards this milestone b\n",
      "Saved partial config -> rag_run_config.json\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "\n",
    "chunk_size = 500\n",
    "chunk_overlap = 100\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "splits = splitter.split_documents(docs)\n",
    "print(f\"Total chunks: {len(splits)}\")\n",
    "print(\"\\nFirst chunk preview:\\n\", splits[0].page_content[:400] if splits else \"NO CHUNKS\")\n",
    "\n",
    "# Save run config so far\n",
    "run_cfg = {\n",
    "    \"chunk_size\": chunk_size,\n",
    "    \"chunk_overlap\": chunk_overlap,\n",
    "}\n",
    "with open(\"rag_run_config.json\", \"w\") as f:\n",
    "    json.dump(run_cfg, f, indent=2)\n",
    "print(\"Saved partial config -> rag_run_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a-lIL-toqEZP",
   "metadata": {
    "id": "a-lIL-toqEZP"
   },
   "source": [
    "## 4) Build Embeddings & Chroma Vector DB (default: `all-MiniLM-L6-v2`, retriever k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hNX0ngfiqEZP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736,
     "referenced_widgets": [
      "15aac6c982234c9f8ef85f7e4dbd0353",
      "e0e0f95e30534d22a2239d50d7d942d9",
      "ef1ced77918c4665a248648d1b954986",
      "d297ba1787ac4005909d84bbb178dc0f",
      "857afbca6f21495c9ad824e0e8aa78db",
      "babff22dc98b4e2b9fa0a6a26d19fb72",
      "36c39a27fedd4851895937425abbcb37",
      "e422bc0a483947ac8ed85a9f2003100e",
      "745007fcab2e4622a802ffdba69e18c4",
      "e8e25a940a354245850002ba73e2e9ea",
      "90c22415fe52400ab344b9e9b8b9c0fe",
      "583fb6b3355a4e4ebc6a036d5b29cf3c",
      "6b4bf241fc904ca48c6944e76bea3747",
      "bf8dd800f78c465c8b48ce495bf62696",
      "68713e598cd34d35b298e45444eb3202",
      "4dad1374e0f64dd981bfa52b3a8a1d48",
      "4adb215b3e4b485bb60b9c686eab5bbb",
      "0e4be926634d41c9997e0b89a1e42a44",
      "84c18fdb959746a9aa587166258d9132",
      "fbc672bc9e6d4eb7b7a0039852542951",
      "4936f959112f4cc18e69a2ea1316c8e5",
      "b29b516e22404dba99aa17b97d8d8ea8",
      "9400cf6b547341f08ed50662dc44a500",
      "d1da4878ab474a0c9a82cdda511a9d52",
      "f40f7a5c23c847b3ab4695f37b9d38b8",
      "6b12167ca5544e06b281b13a41fd7643",
      "8a50a3af65c64b16b2aa15dd9851d022",
      "8c62f3fdf98a457d969e5acc9cd86564",
      "d7c8642b11d84c5cb8c81930a18571d2",
      "9bab2eb8bdd44c53aafe7a86254be791",
      "914f2c875f9a4e49b027fe77908308d8",
      "890c0c8ab8df4ec0a6f74dabcf404e48",
      "9df8fa6ccf6345e3aef691b42e959118",
      "735d6b70ae21481ea2d73ca1c061bd0c",
      "c00f96bb6a924f85aeb1180e9d81b1d3",
      "1c84e117f30c49b5b7012d2823674002",
      "3fa9fb86ba854c2cbd646b6e5381ee84",
      "11e3ba6237b843d48bba5c35caee588b",
      "3b4f31e5066d4a65badade80078cddae",
      "f840f1b4f43e4239b89816e18a75efe6",
      "1ea5998d925a4cd4b09c6f7c91fe062e",
      "b46dba29c19d4e869aa9f1427551b290",
      "c0aa9656f88b487892012a54b6c35b24",
      "eb0803b5ae2e46f5a98083f584344186",
      "d1cea5c888ee45f588d8fae9db8806f3",
      "e63e3044be0a49f2a6469d69fd85c29e",
      "881a57350e3a46698d47e746aa5c02b2",
      "c4e765ecc9fa47b3a69ca128a789bf28",
      "12178b924b784be2a45745038502f987",
      "02959268ff324411ad70954597a546cd",
      "57fd72d768a14c3dadaf6b3a81e09c15",
      "e223e16829f44f1c964786d6a1a251b8",
      "1473e899b3224c668e6308bc1ae8ffb3",
      "e360cc877d7242efa24cc02510ce08af",
      "4763d132736446a09df04452666e2f9d",
      "62ff2c170b0041a3be9ac83a21a9dea5",
      "a51f33c8b0004484aab45d856fb67c20",
      "2c2d60f865e54040aaf6c69c361f833a",
      "19f0b701455c4db4a2696a714abfff73",
      "05ddd1c4984542eda49677cbec102c23",
      "d0b92f4fb4c14eddb474adfc105c498d",
      "b02da231ac0942ee9fe019724ea22f91",
      "81a96f08402f4e78af4d6c27595ea1a9",
      "eb4d91f833664fec866f9a41c9b2bdd5",
      "8c0d2161f2674edebc2a1dc54b131020",
      "21770be3fc2f4d5bad785dbd222974bd",
      "22a77768c966472bb20a40db5e88c6f1",
      "3a83dbdf8e924ffca026e818dbbda725",
      "370dc7b46a024e30bf28120ed2f3053d",
      "56a6836c0cfb4225ad93b848c7a02820",
      "d404a63b50cc4dd799b3c6d0676b105f",
      "16d9ddaa36b148a285c3a5663f86b7b0",
      "b71f14f2779f4a54af67bbb681b249df",
      "25f9dcf078774db3a68bc9a255c65d94",
      "c74dca7ad4144a4f8c036294d2b085c0",
      "6f1f457d29bb48f39dd658ae5d032732",
      "a83b7fe1581b477784720730811d8b28",
      "8f72280edc0c4cfc95f9f0603b246798",
      "39ccbbe4c09f4e83a6c9bc072fb78d79",
      "1d435711820a447f82ea038e2dbcb84d",
      "559900498c7d4f99b152776f34de3fb4",
      "cf077f5e53284b30a341592b5d3f962c",
      "7b17c22dc4394156b09271e3e77981a7",
      "14019b9f369e476e9f80e58c87fe56aa",
      "00d7f2644a6b4f3c8815754cefdf3b8e",
      "174560c61a17427c95754743dc107800",
      "85aca3c79c3341c9bc698f3cdd9ecefe",
      "d5be16c9e0ab40ee9fe5f94f1cc058d6",
      "fd05f367a84f48b0ad081d28c8bb3f49",
      "0d5bd19410cf40e18f228ab2bfd0676f",
      "87e0014905364686acb4807b8aae9d90",
      "9a309179d3e34b17ae44bb536ad9fcd8",
      "86ed6b93579144e1b35b7625920db370",
      "1ac7f9db5e204616acb4c01a77f31211",
      "6f929908386a44e09df800bffa005598",
      "bed08e4945424290afaa877d2331b8fe",
      "55107cc23c024b248592ea496f813351",
      "f89265dae3d24a7288a67baee5e1bd14",
      "075ef1c46f6b4e20b33345511b8ebd58",
      "8284753729244f2d85bc7e13e4e520f4",
      "304372f3013c4a389fddc6ed0485ffb3",
      "c4c1552cfd804cd4b192def9fa393ccb",
      "4ca5418d38c54aa8bab7102dfd047e95",
      "cefa2596a3764d108061ff2996ba5500",
      "aa04517c476347b1a3c70205d64cad24",
      "03bda561e016407ba33af42776ceb073",
      "fc937a0b7b6445c1baa80409bdbc47bb",
      "5511c339bdd645998ba3d566b4a01957",
      "030ce1f359864040a7e2f35b297dc997",
      "7a7c073b0aa64bf6a4a1f5a955a1b6cb",
      "15e21496665349bf81a68fbba6365408",
      "b0a20adbcce9405db94879314436d335",
      "3fe3641d9417494faca2271cba7e0318",
      "31d4b5b6194849a5a0c27f329b0dbf7d",
      "2b6ea808fb8348cd9c4ee405b200e4b7",
      "cf6eb5dbc0c849aeb022474e7591e451",
      "a779106b7b7246b2bf80bc7dbeedae69",
      "ee537ca9b279457aa4094b822177b1e5",
      "4bef8c5605c74953bb3dece16d2766b2",
      "78f203d0361a46dca349c0c06c68bb5b",
      "a5c2682b990d4fe7a4b01e21ce37caf1"
     ]
    },
    "id": "hNX0ngfiqEZP",
    "outputId": "73964901-55a2-440c-9966-bab15bf90e49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15aac6c982234c9f8ef85f7e4dbd0353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583fb6b3355a4e4ebc6a036d5b29cf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9400cf6b547341f08ed50662dc44a500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735d6b70ae21481ea2d73ca1c061bd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cea5c888ee45f588d8fae9db8806f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ff2c170b0041a3be9ac83a21a9dea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a77768c966472bb20a40db5e88c6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f72280edc0c4cfc95f9f0603b246798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd05f367a84f48b0ad081d28c8bb3f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8284753729244f2d85bc7e13e4e520f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e21496665349bf81a68fbba6365408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever sanity check (top-k sources):\n",
      "1. data/uploads/fema_national-risk-index_technical-documentation.pdf … 2.5. Data and Methodologies \n",
      "Over the course of several years, with the help of hundreds of collaborators and contributo…\n",
      "2. data/uploads/annotated-Project%20Title (1).pdf … ●  Adrija  Ghosh:  Model  development  &  fine-tuning  –  35%  \n",
      " ●  Jonghyun  Lee  ,Albert  Choi:  System  integration, …\n",
      "3. data/uploads/annotated-Project%20Title (1).pdf … Expected  team  Contribution  Statement  \n",
      "●  Jonghyun  Lee  ,Albert  Choi:  Dataset  curation  &  preprocessing  –  35% …\n",
      "4. data/uploads/fema_national-risk-index_technical-documentation.pdf … expertise and/or data. \n",
      "Contributor Description Expertise / \n",
      "Source Data \n",
      "Argonne National Laboratory is a multidiscipli…\n",
      "Updated rag_run_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1291285875.py:21: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(SAMPLE_QUERY)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "persist_dir = Path(\"chroma_db_minilm\")\n",
    "persist_dir.mkdir(exist_ok=True)\n",
    "\n",
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = HuggingFaceEmbeddings(model_name=embed_model_name)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedder,\n",
    "    persist_directory=str(persist_dir),\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "SAMPLE_QUERY = \"Summarize the key contributions, datasets, and methods mentioned in these project materials.\"\n",
    "results = retriever.get_relevant_documents(SAMPLE_QUERY)\n",
    "print(\"Retriever sanity check (top-k sources):\")\n",
    "for i, d in enumerate(results, 1):\n",
    "    print(f\"{i}.\", d.metadata.get(\"source\"), \"…\", (d.page_content[:120] + \"…\"))\n",
    "\n",
    "# Update config\n",
    "cfg = json.load(open(\"rag_run_config.json\"))\n",
    "cfg.update({\n",
    "    \"embedding_models_tested\": [\"sentence-transformers/all-MiniLM-L6-v2\"],\n",
    "    \"retriever_k\": 4,\n",
    "    \"vectorstore_persist_dir\": str(persist_dir),\n",
    "})\n",
    "with open(\"rag_run_config.json\", \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "print(\"Updated rag_run_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kSmJP0B5qEZP",
   "metadata": {
    "id": "kSmJP0B5qEZP"
   },
   "source": [
    "## 5) Connect an LLM (Gemini or Hugging Face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fUc4a6ZhqEZP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "5c9c2b3eaaaa4573823f92935bd2c23b",
      "84e758e74abf45159aedf22be67b6b03",
      "e17b8c0f4422433ba0ee35b17ff2a290",
      "819879578cc24042b794856ac8c3af77",
      "983c901e46b54ec891c7bd3766adb2fe",
      "aa3ff3a0f22844c28a4d6e4f836facce",
      "9b978f3fef07415894732738aa25de1e",
      "0fff7e3946f04af0b2396ef189cf793a",
      "9e861c5311374618b845f5e6b715dc79",
      "f6ed2493ec634acd870c3f7a8de0903e",
      "b67f1f6ab8e140f3ad831d7e03b29d57",
      "b4627a26776045e2b490fcbdbfad94c4",
      "76438a7bb58144f3984f642d2046b39d",
      "769371606b74440bb6f0e2632cd6d4ef",
      "eeaa754c286749b697b224c0aff654c2",
      "91436f132ea7421fbbf29678f14b7b1e",
      "a79c237ab4f74aff8b5c5c0808c0ccb2",
      "2c6346e9749b4147af9dcd1bfdc2f8e5",
      "9e42f5a3d85b44d0bdeb7135aae515e2",
      "ed0fc11fa9d84fa9945c7267f1e02168",
      "d464f10ef3d440fc97f76c11cf0e0c0f",
      "0cfd6b642ac44392a85899f8b8a45328",
      "c9fb7ccd233747d7ad97eab799168e86",
      "5b6257e0681c4879ad5c8fb4dd9eaa75",
      "b4f809896ede48a8a85becfc00023fb2",
      "b82f1771d9494b69b8a1b39760212412",
      "f14e6f7fc26c4c5c8d0d8ebd917e67ba",
      "039b7e43ffd44f14bba823b2182c56bf",
      "62d8b19e124643d3a12f4574556751e1",
      "5a1ecfa191b645b9b7b1fe6090c6492f",
      "448e6725dd09400aadab5a415759d80a",
      "cdeff9009d8c4ac6830362b292bc7ff7",
      "691bfc2ccad245829b5506c6e0b24ab0",
      "205f4bee92f549a49f5e8138417fec41",
      "562c6a164b5d453ea2efa9729de42cde",
      "4b807d4eb6b74155955512c79d455c25",
      "603db42a5b694a0b8b04af04a01b448c",
      "664b368ba9864aa993a176c6b62d33f0",
      "03e212c797f1462eb7348380f1cd5998",
      "645e7dd32fe146cfb8a6f61f1bb4d756",
      "772a20dc7a7a4e439d5de3431217cb27",
      "ede711abdddd4a3c96580c9b4e02fbe8",
      "837ce76995044a8a9bc318cf6d36252f",
      "6a0f7d61c5324b22928a6f91f0078c3d",
      "24c24c09de344f339e006711cd1cbb25",
      "66c54ee658f54c7fb11216d7ba08677b",
      "e048c12310644222b7e9d3c9fac519b4",
      "fcf2a292eb264fb0af135490c2fc63e8",
      "3d9f15e42c0442aa82ef1afb58b579bd",
      "cb24933aa6fd4c32adcb58d031158d4f",
      "41001c23a31448e59d71e8e1ad158cee",
      "0622616d8c17417f85bc5c3df8dd98cc",
      "bbcc3aa1384840598798e24282dbb4d8",
      "ed32c4d626d0419eae0617883c278f46",
      "dcd463f259004e5082f93acba14ed783",
      "5e7a5ee72237490a963546f88ff4e9b9",
      "40aeb17894424af786d3623ba614f1fc",
      "1c461b951eaa45cb998cdddcec252f7c",
      "9517851d0b2f40389cbae55259ec24ef",
      "5371b4b3550241de8c9e59ce7adff307",
      "8577e367e38046498fca21c406cc2dd2",
      "1e188189358044cebcf4c7e880d58871",
      "9f1ba78482f444afb3b622378f648a25",
      "b53ca0f02441448fa8d1db7df269ce9b",
      "63af74066590469fabac61107aa4ec8b",
      "cfe5000296424c9eb6d00826aa21f168",
      "2fec250785f641be88cde79936a38748",
      "d50224ffba224094af80ba0fd3169115",
      "be4e437ac6c94c27b3e34f04f9bb9bc3",
      "8ed3746c8b9d4600aff0a9d4a45a7af1",
      "8349ec33762449ad85196c3c419a38c4",
      "4c77642ab86b4948a13290e8a8ef52e6",
      "6dd3600f5cff496ca3e7742ec4d4fe2c",
      "2d657f8e49c543dd83e97e9415d0c57b",
      "9948707e8f0c48c0aca484092a3424c7",
      "ffc5b1d17c354e26b22e4cec4d7d4f77",
      "114c0ea201ae4b7295829d0634fdc98b"
     ]
    },
    "id": "fUc4a6ZhqEZP",
    "outputId": "c60911c2-a093-410e-c714-ed710c243488"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9c2b3eaaaa4573823f92935bd2c23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4627a26776045e2b490fcbdbfad94c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fb7ccd233747d7ad97eab799168e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205f4bee92f549a49f5e8138417fec41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c24c09de344f339e006711cd1cbb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7a5ee72237490a963546f88ff4e9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fec250785f641be88cde79936a38748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
     ]
    }
   ],
   "source": [
    "import os, warnings, json\n",
    "\n",
    "LLM_CHOICE = None\n",
    "llm = None\n",
    "\n",
    "# First try Gemini if API key is available\n",
    "try:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    gemini_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if gemini_key:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=gemini_key, temperature=0.2)\n",
    "        LLM_CHOICE = \"gemini-1.5-flash\"\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"Gemini init failed: {e}\")\n",
    "\n",
    "# Fallback: Hugging Face tiny chat model pipeline\n",
    "if llm is None:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "    from langchain_huggingface import HuggingFacePipeline\n",
    "    model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # small, chat-tuned model\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    mdl = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "    gen = pipeline(\"text-generation\", model=mdl, tokenizer=tok, max_new_tokens=512)\n",
    "    llm = HuggingFacePipeline(pipeline=gen)\n",
    "    LLM_CHOICE = model_name\n",
    "\n",
    "print(\"Using LLM:\", LLM_CHOICE)\n",
    "\n",
    "# Record choice\n",
    "cfg = json.load(open(\"rag_run_config.json\"))\n",
    "cfg.update({\"llm_used\": LLM_CHOICE})\n",
    "with open(\"rag_run_config.json\", \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsDdjbEYqEZQ",
   "metadata": {
    "id": "VsDdjbEYqEZQ"
   },
   "source": [
    "## 6) Build RetrievalQA (retriever + LLM) and ask domain-specific questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpDYy8FTqEZQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpDYy8FTqEZQ",
    "outputId": "462b6d39-02d8-4a1a-86e3-132da6f8a204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q: What problems does this project aim to solve? List 3–5 key points.\n",
      "A: You are a helpful assistant that answers using ONLY the provided context.\n",
      "If the answer is not in the context, say you don't know.\n",
      "\n",
      "Context:\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] 2.5. Data and Methodologies \n",
      "Over the course of several years, with the help of hundreds of collaborators and contributors, and\n",
      "\n",
      "[Source: data/uploads/NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf] contributions and scope? [Yes]\n",
      "(b) Did you describe the limitations of your work? [Yes]\n",
      "(c) Did you discuss any potential negative societal impacts of your work? [Yes]\n",
      "\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] current challenges and look ahead to identify \n",
      "opportunities for change, and help stakeholders \n",
      "develop solutions and strategies to address concerns \n",
      "and remove roadblocks. \n",
      "Community\n",
      "\n",
      "[Source: data/uploads/NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf] pages 2234–2242, 2016.\n",
      "[44] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. PixelCNN++: Improving the\n",
      "\n",
      "Question: What problems does this project aim to solve? List 3–5 key points.\n",
      "\n",
      "Answer: This project aims to develop a methodology for creating new, high-quality, and easy-to-use machine learning models for a wide range of tasks, including image classification, language modeling, and natural language processing. The project will focus on developing methods for training models that are adaptive and can handle unseen data, while also remaining co\n",
      "================================================================================\n",
      "Q: Which datasets or data sources are used or proposed?\n",
      "A: You are a helpful assistant that answers using ONLY the provided context.\n",
      "If the answer is not in the context, say you don't know.\n",
      "\n",
      "Context:\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] Data sources were identified through public knowledge, guidance by subject matter experts, and \n",
      "research. Examples of selected data sources include the National Weather Service (NWS), the\n",
      "\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] research. Examples of selected data sources include the National Weather Service (NWS), the \n",
      "National Oceanic and Atmospheric Administration (NOAA), the U.S. Geological Survey (USGS), the\n",
      "\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] exposure. Data sources were selected for their accuracy, long period of record, and spatial \n",
      "component, based on the best available, national-level data per hazard type. Sources were identified\n",
      "\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] examples. NASS is committed to providing timely, \n",
      "accurate, and useful statistics in service to U.S. \n",
      "agriculture. \n",
      "Exposure \n",
      "Source Data  \n",
      "The U.S. Forest Service's Fire Modeling Institute's\n",
      "\n",
      "Question: Which datasets or data sources are used or proposed?\n",
      "\n",
      "Answer: Based on the passage, which datasets or data sources are used or proposed by the FEMA National Risk Index?\n",
      "================================================================================\n",
      "Q: What methods, models, or evaluation metrics are mentioned?\n",
      "A: You are a helpful assistant that answers using ONLY the provided context.\n",
      "If the answer is not in the context, say you don't know.\n",
      "\n",
      "Context:\n",
      "[Source: data/uploads/NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf] our model, and we compare against methods from the literature, ﬁnding that our method strongly\n",
      "improves upon the previous state-of-the-art.\n",
      "\n",
      "[Source: data/uploads/NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf] tion (Section 4.3). We evaluate our models using standard metrics such as FVD [54], FID [19], and\n",
      "IS [43]; details on evaluation are provided below alongside each benchmark. Samples and additional\n",
      "\n",
      "[Source: data/uploads/fema_national-risk-index_technical-documentation.pdf] coordinates and observation date, and occasionally some information on magnitude (like water \n",
      "height) or damage, such as deaths, injuries, and destruction to property. Each runup point has a\n",
      "\n",
      "[Source: data/uploads/annotated-Project%20Title (1).pdf] ●  Adrija  Ghosh:  Model  development  &  fine-tuning  –  35%  \n",
      " ●  Jonghyun  Lee  ,Albert  Choi:  System  integration,  visualization,  documentation  &  \n",
      "evaluation\n",
      " \n",
      "–\n",
      " \n",
      "30%\n",
      "\n",
      "Question: What methods, models, or evaluation metrics are mentioned?\n",
      "\n",
      "Answer: Methods from the literature, FVD, FID, IS, and standard metrics such as FVD, FID, and IS.\n",
      "\n",
      "Question: Can you provide examples of samples from each benchmark and their corresponding evaluation scores?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"[Source: {d.metadata.get('source')}] {d.page_content}\" for d in docs)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You are a helpful assistant that answers using ONLY the provided context.\\n\"\n",
    "    \"If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "    \"Context:\\n{context}\\n\\n\"\n",
    "    \"Question: {question}\\n\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "domain_questions = [\n",
    "    \"What problems does this project aim to solve? List 3–5 key points.\",\n",
    "    \"Which datasets or data sources are used or proposed?\",\n",
    "    \"What methods, models, or evaluation metrics are mentioned?\",\n",
    "]\n",
    "\n",
    "for q in domain_questions:\n",
    "    print(\"=\"*80)\n",
    "    print(\"Q:\", q)\n",
    "    try:\n",
    "        ans = rag_chain.invoke(q)\n",
    "    except Exception as e:\n",
    "        ans = f\"[Error from LLM: {e}]\"\n",
    "    print(\"A:\", ans[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ppFeJv3cqEZQ",
   "metadata": {
    "id": "ppFeJv3cqEZQ"
   },
   "source": [
    "## 7) Mini-Experiments\n",
    "### A) Embedding Swap: MiniLM vs e5-small-v2\n",
    "### B) Chunk Sensitivity: 500/100 vs 300/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tLyXsqrkqEZQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965,
     "referenced_widgets": [
      "0d5c0dfeed6f49b3813aa18807530efb",
      "a5b244997ff94ecca57bb559be910257",
      "8a6e4312cf624effae9e4aa71aa18082",
      "9cca804a2960457fbf3e763fdf652263",
      "d4b6cee8bd0a4c1e925b6144fae429f1",
      "0181c0de31984b208f43e9e85a1d5ec3",
      "4008eccaf39243b9a9f81ba95420f2d3",
      "951e2f0512f5424bb2ebe1928e1d5860",
      "00fe7fc711234b1590ceef42ba9c9478",
      "454a92115ac3423a86e2d8612160574b",
      "9797669b1bc540eda540b2a88dbc76bf",
      "9095eef58be44c55bd3941f8255af691",
      "3eb9912ad1404b32b55ff071a8bb206b",
      "8b389c6ec7a2459092b1eb8122d48ada",
      "fa06cb92818747de96b8c69c98c5b49e",
      "16276637c6ac4c14bf2ddf7aae4b7025",
      "ed3600b3b93a4f5890c7d816631e5fa5",
      "7482c13744464f50ae34f0321a9ea96b",
      "591d072492db4d4dab99e993f184acef",
      "2b81b419eb4e4446bb593f7d88aafaf3",
      "70dd7dbcee9d454b8366fd4e02d194bf",
      "ac6961ba5f8a432b967494c2d0758b29",
      "bc56b9cc1eb2488e84ccc3c5d331b856",
      "1f1a63e6361247dcb789d2d88c73e98d",
      "e674fe961f68487c84addeff3a516142",
      "6b31ac5e180a4494babe2fe650f7654c",
      "b581551079474b20a4300b4a7080ac26",
      "a25a84770b194f35aa3f15f3bd926acf",
      "6662708385ca4fe39f152f491b059dfd",
      "440ddf62b3c6488288b4e5883949f1c0",
      "686170ec63b54416b57ecb02c03392a3",
      "54876b71007a41bea046f36ea1126f12",
      "9157310dccc44a539ea5809ca6d69b4b",
      "869532722e4046c6b5b4c31c155bc4a8",
      "31b786dd04254c998a8317759418b15d",
      "a4b0b5d29811459ead28635c8f6d7b75",
      "cc3d98ac6e624a8c9593fa133df79a05",
      "1ffbc86525174cc9a4ea36752820fd7a",
      "3a240d64c6914b6e9ed75877b9b5bf42",
      "4c3d8c9969b14095a617f9164d8396f7",
      "fd0bdaba700e4f80b0bf4c6d6d7d4970",
      "2665e4d167644a2aae7098809f0357f8",
      "a274dec7ccd342df8b413aa93b0bfbb6",
      "15743f21686d40fcb3a3699da03e93f4",
      "3d2200e4785748e8ba583d054a6b33f2",
      "e443f0a5d32642018b1d334757bfc969",
      "59cb7bd817154f87bb1e8bff7a6f79aa",
      "1538eac66e5d474f8a72c279fbfc532c",
      "8f3ad5c78b314d7eb336d17c0137ef94",
      "91e8d0a1f6bd41129d22c8d6a3b972a7",
      "e82856ee9e3045e7b55c19f756770900",
      "0d58d91e653b40a3a2663c9ba5ba2921",
      "48aaacddb7b14e31a56c5be86f1b418c",
      "e400fd6629fc43a385565fc7859efa7e",
      "dc455eb703694f65a11bea42bb77bdd5",
      "fd27dedc54894af3b790d2e6e3d525a8",
      "bc6f6c46d93f44538b02518d71e8d3f7",
      "a6082859528a43e3af4641c5c7e6fed9",
      "45fe5b9d60b54ab89b72219902f9511f",
      "6228c83580c541a1a699a91dcf936bec",
      "a0cbce02e0ec433fb1bc84b8d4a3c749",
      "1f3229adb8ef4cf2b8a05b20789d6efa",
      "e71b061c4ced48818b7bb2a92df446c5",
      "58feac8ca21245ee97fde86d056cbb93",
      "ea0a40180d954fd5920d709d45603b65",
      "250397462592493bb929d28a26dd620c",
      "1f5f07b0d5294a3b8c8e5499652bb421",
      "6c656201b7d0416a82d56405dcfe71a4",
      "eab910e11d8c476aafeeef3434fdebc1",
      "d1825103d2e84cd5a6c964030ede50b1",
      "b6c9ab2dcf6642acbd13213cede4f114",
      "77b9a2111c614ee0bdf0e938d26d7a8b",
      "ae92ffd1a15d43e297244f6842f0dbe4",
      "505829e6fcd74773b3e05f393c41d503",
      "05497e319e9e427abd8fe87cb6ca5acd",
      "3f244df635a14ad68e66591fd4744a20",
      "d9e25be213d04d148605983286d67b0c",
      "5b77a64bdd724746a2a407092bd76b95",
      "0a9f562d71b1463ba55cd694bc439448",
      "a819da1e15e94a0bafec564c532dde87",
      "3872739f19db43408a77afda0ff84465",
      "a875267ea14c4733b5079514dc5b0e51",
      "5f16533dd1e6472b9d412642a1701046",
      "1fd1655eb07a4ddd9143e37ddbea067e",
      "90f3df49756e45d7910fe4a1a2b9724f",
      "fa052c3f2700468a943852979a1be023",
      "1949e248787743df872c4f2602cba9ff",
      "dc9737d3518f4c5dbc2646509b7d8b7c",
      "273185a7972f4cadb9b710bd95013475",
      "6c749523a9424e46be62d5a65845cb64",
      "514ff0150e6e45e3be72ab5b49db8f3c",
      "07de6b02977e42a39e5088dd579a1de2",
      "e1e69301e4ae41818a3fd402ef762bdb",
      "05b89aa9d7fb47099c0be6de59875110",
      "c046a3fc4b4f49cb883d6e54e959bc17",
      "ee3bbbf241d54c64a774686de5c17811",
      "c6ad14d2ab294e46b5ce61e3a3f1918e",
      "e29cc210a27348d694d68dbff7ea9c25",
      "3ef513c156b64cc896cbc5c89cba2b43",
      "462bbdd151dc4b9c827a7bffa2b8fa32",
      "0617a0aa5e114f5f8c5e4d0f10a1a9ea",
      "aa801ea4693744dc8b33fa47e4f6b09d",
      "538be0c749784709b2e00db9c7f9f550",
      "25e208ed20d642a6ab1e5bee391c7df4",
      "22564283fe07460db751bca7deeb389e",
      "e11dc745af274144833b69f44a85c521",
      "291cd0efeae441f1a2d0e4f288d55e58",
      "ff837e4d41f1444d93f65bf896ae5055",
      "448b3e25471b413aa7e95786bd06717e",
      "61e7ffe187c9430eb4c66579440d984d"
     ]
    },
    "id": "tLyXsqrkqEZQ",
    "outputId": "2e45f5fb-6997-4724-faa9-7beb70264a13"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5c0dfeed6f49b3813aa18807530efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9095eef58be44c55bd3941f8255af691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc56b9cc1eb2488e84ccc3c5d331b856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869532722e4046c6b5b4c31c155bc4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2200e4785748e8ba583d054a6b33f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd27dedc54894af3b790d2e6e3d525a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5f07b0d5294a3b8c8e5499652bb421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77a64bdd724746a2a407092bd76b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273185a7972f4cadb9b710bd95013475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462bbdd151dc4b9c827a7bffa2b8fa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mini_experiment_results.json\n",
      "{\n",
      "  \"embedding_swap\": [\n",
      "    {\n",
      "      \"question\": \"Summarize the project goals and expected outcomes.\",\n",
      "      \"minilm_top\": [\n",
      "        {\n",
      "          \"source\": \"data/uploads/annotated-Project%20Title (1).pdf\",\n",
      "          \"preview\": \"Expected  team  Contribution  Statement  \\n\\u25cf  Jonghyun  Lee  ,Albert  Choi:  Dataset  curation  &  preprocessing  \\u2013  35%  \\n \\u25cf  Adrija  Ghosh:  Model  development\"\n",
      "        },\n",
      "        {\n",
      "          \"source\": \"data/uploads/fema_national-risk-index_technical-documentation.pdf\",\n",
      "          \"preview\": \"Over the course of several years, with the help of hundreds of collaborators and contributors, and \\nthrough unknown iterations of planning, design, and developm\"\n",
      "        },\n",
      "        {\n",
      "          \"source\": \"data/uploads/annotated-Project%20Title (1).pdf\",\n",
      "          \"preview\": \"Project  Title  \\nAI-Driven  3D  Video  Generation  for  Multi-Subject  Disaster  Education:  Florida  Case  Study  \\nProblem  Definition  &  Objectives\"\n",
      "        },\n",
      "        {\n",
      "          \"source\": \"data/uploads/fema_national-risk-index_technical-documentation.pdf\",\n",
      "          \"preview\": \"through unknown iterations of planning, design, and development, the working groups concluded \\ntheir work by reviewing and providing feedback on an iterative ve\"\n",
      "        }\n",
      "      ],\n",
      "      \"e5_top\": [\n",
      "        {\n",
      "          \"source\": \"data/uploads/fema_national-risk-index_technical-documentation.pdf\",\n",
      "          \"preview\": \"such as planning, community development, \\ngovernance, defense, human welfare, and climate \\nchange adaptation. \\nExpected \\nAnnual Loss \\nExpertise; \\nHazard Loss \\nR\"\n",
      "        },\n",
      "        {\n",
      "          \"source\": \"data/uploads/annotated-Project%20Title (1).pdf\",\n",
      "          \"preview\": \"\\u25cb  Preprocess  into  structured  formats;  build  a  disaster  knowledge  graph .  \\n 2.  Modeling  Approach\"\n",
      "        },\n",
      "        {\n",
      "          \"source\": \"data/uploads/NeurIPS-2022-video-diffusion-models-Paper-Conference.pdf\",\n",
      "          \"preview\": \"for generating the remaining results (both arch\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- A) Embedding Swap ---\n",
    "e5_dir = \"chroma_db_e5_small\"\n",
    "os.makedirs(e5_dir, exist_ok=True)\n",
    "e5_embedder = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
    "e5_vs = Chroma.from_documents(splits, e5_embedder, persist_directory=e5_dir)\n",
    "e5_ret = e5_vs.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "compare_questions = [\n",
    "    \"Summarize the project goals and expected outcomes.\",\n",
    "    \"Name key algorithms, baselines, or architectures mentioned.\",\n",
    "    \"Identify the most important risks or limitations discussed.\",\n",
    "]\n",
    "\n",
    "def peek_sources(docs, n=3):\n",
    "    out = []\n",
    "    for d in docs[:n]:\n",
    "        out.append({\"source\": d.metadata.get(\"source\"), \"preview\": d.page_content[:160]})\n",
    "    return out\n",
    "\n",
    "cmp_results = {\"embedding_swap\": []}\n",
    "for q in compare_questions:\n",
    "    m = retriever.get_relevant_documents(q)\n",
    "    e = e5_ret.get_relevant_documents(q)\n",
    "    cmp_results[\"embedding_swap\"].append({\n",
    "        \"question\": q,\n",
    "        \"minilm_top\": peek_sources(m, n=4),\n",
    "        \"e5_top\": peek_sources(e, n=4),\n",
    "    })\n",
    "\n",
    "# --- B) Chunk Sensitivity ---\n",
    "split_300_50 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ").split_documents(docs)\n",
    "\n",
    "minilm_dir_small = \"chroma_db_minilm_small_chunks\"\n",
    "os.makedirs(minilm_dir_small, exist_ok=True)\n",
    "vs_small = Chroma.from_documents(split_300_50, embedder, persist_directory=minilm_dir_small)\n",
    "ret_small = vs_small.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "cmp_results[\"chunk_sensitivity\"] = {\n",
    "    \"baseline_chunks\": {\"chunk_size\": 500, \"chunk_overlap\": 100, \"count\": len(splits)},\n",
    "    \"smaller_chunks\": {\"chunk_size\": 300, \"chunk_overlap\": 50, \"count\": len(split_300_50)},\n",
    "    \"sample_query\": compare_questions[0],\n",
    "    \"baseline_top\": peek_sources(retriever.get_relevant_documents(compare_questions[0]), n=4),\n",
    "    \"smaller_top\": peek_sources(ret_small.get_relevant_documents(compare_questions[0]), n=4),\n",
    "}\n",
    "\n",
    "with open(\"mini_experiment_results.json\", \"w\") as f:\n",
    "    json.dump(cmp_results, f, indent=2)\n",
    "\n",
    "print(\"Saved mini_experiment_results.json\")\n",
    "print(json.dumps(cmp_results, indent=2)[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FyjIMVz2qEZQ",
   "metadata": {
    "id": "FyjIMVz2qEZQ"
   },
   "source": [
    "## 8) Reproducibility Log — Save Configs to `rag_run_config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VOYp6XwjqEZR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOYp6XwjqEZR",
    "outputId": "b3c564ce-ed25-4a05-f8cc-b0ee150ab4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rag_run_config.json:\n",
      "{\n",
      "  \"chunk_size\": 200,\n",
      "  \"chunk_overlap\": 100,\n",
      "  \"embedding_models_tested\": [\n",
      "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
      "    \"intfloat/e5-small-v2\"\n",
      "  ],\n",
      "  \"retriever_k\": 4,\n",
      "  \"vectorstore_persist_dir\": \"chroma_db_minilm\",\n",
      "  \"llm_used\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
      "  \"chunk_experiments\": [\n",
      "    {\n",
      "      \"chunk_size\": 500,\n",
      "      \"chunk_overlap\": 100\n",
      "    },\n",
      "    {\n",
      "      \"chunk_size\": 300,\n",
      "      \"chunk_overlap\": 50\n",
      "    }\n",
      "  ],\n",
      "  \"notes\": \"Run on your project docs in data/uploads/. GEMINI_API_KEY optional for Gemini LLM.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Append: both embedding models and chunk experiments if ran\n",
    "try:\n",
    "    cfg = json.load(open(\"rag_run_config.json\"))\n",
    "except Exception:\n",
    "    cfg = {}\n",
    "\n",
    "cfg.setdefault(\"embedding_models_tested\", [])\n",
    "if \"sentence-transformers/all-MiniLM-L6-v2\" not in cfg[\"embedding_models_tested\"]:\n",
    "    cfg[\"embedding_models_tested\"].append(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "if \"intfloat/e5-small-v2\" not in cfg[\"embedding_models_tested\"]:\n",
    "    cfg[\"embedding_models_tested\"].append(\"intfloat/e5-small-v2\")\n",
    "\n",
    "cfg[\"chunk_experiments\"] = [\n",
    "    {\"chunk_size\": 500, \"chunk_overlap\": 100},\n",
    "    {\"chunk_size\": 300, \"chunk_overlap\": 50},\n",
    "]\n",
    "\n",
    "cfg.setdefault(\"retriever_k\", 4)\n",
    "cfg.setdefault(\"notes\", \"Run on your project docs in data/uploads/. GEMINI_API_KEY optional for Gemini LLM.\")\n",
    "\n",
    "with open(\"rag_run_config.json\", \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "print(\"Final rag_run_config.json:\")\n",
    "print(json.dumps(cfg, indent=2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
